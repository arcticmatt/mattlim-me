---
title: Blindsight
date: '2023-03-05'
category: Books
tags: scifi, books
summary: 'Instead of asking "what is consciousness", try asking "why consciousness"'
---

## Summary
Everything changed when the Fireflies attacked. Well, they didn't really attack—they *surveyed*. Ok, let me clarify. The story starts with these so called "Fireflies" (UFOs) coming to Earth to gather information. This spurs humanity to go searching for the source of the Fireflies. The search crew, which is onboard a ship named *Theseus*, is composed of Siri Keeton (the main character and narrator of the story), Susan James (to communicate with the aliens), Amanda Bates (military person), Isaac Szpindel (biologist, to study the aliens), Sarasti (a superhuman vampire), and Captain (an advanced AI that captains the crew).

Eventually, they find a [sub-brown dwarf](https://en.wikipedia.org/wiki/Sub-brown_dwarf) nicknamed Big Ben and a UFO orbiting the dwarf. To the crew's surprise, the UFO is ability to communicate via human language, and calls itself *Rorschach*. In order to learn more about *Rorschach*, which is likely responsible for sending the Fireflies, the crew sends in drones. Unfortunately, due to *Rorschach*'s strong electro-magnetic waves, the drones are rendered dysfunctional soon after they enter. Thus, the only way to continue exploring is to send the humans themselves.

Even though the human crew can *survive* exploring *Rorschach*, their protective suits are not impregnable, and the EM waves affect each of them in strange and different ways. For example, it makes one of them go temporarily blind, and makes another think that they don't even *exist*.

After a few visits to *Rorschach*, the crew eventually runs into creatures dubbed scramblers, which kinda look like [brittle stars](https://en.wikipedia.org/wiki/Brittle_star)—they have circular bodies with many multi-jointed legs. After a big kerfuffle, the crew manages to capture two alive (it is implied later on that *Rorschach* may have intended for this to happen, so they could spy on the humans) and studies their biology and language.

The ultimate conclusion is that the scramblers are extremely intelligent, but non-sentient. In other words, they have no conscious. They are also reliant on *Rorschach* to survive, and slowly perish outside of its confines. The quote below explains how the scramblers are actually just the output of *Rorschach*—in other words, *Rorschach* itself can be seen as the alien organism.

> "Genes just establish the starting conditions to enable the process. The structure that proliferates afterwards doesn't need specific instructions. It's classic emergent complexity. We've known about it for over a century." Another drag on the stick. "Or even longer. Darwin cited honeycomb way back in the eighteen hundreds." 
> 
> "Honeycomb," Bates repeated. 
> 
> "Perfect hexagonal tubes in a packed array. Bees are hardwired to lay them down, but how does an insect know enough geometry to lay down a precise hexagon? It doesn't. It's programmed to chew up wax and spit it out while turning on its axis, and that generates a circle. Put a bunch of bees on the same surface, chewing side-by-side, and the circles abut against each other—deform each other into hexagons, which just happen to be more efficient for close packing anyway." 
> 
> Bates pounced: "But the *bees* are programmed. *Genetically*." 
> 
> "You misunderstand. Scramblers are the *honeycomb*." 
> 
> "*Rorschach* is the bees," James murmured. Cunningham nodded. "*Rorschach* is the bees. And I don't think Rorschach's magnetic fields are counterintrusion mechanisms at all. I think they're part of the life-support system. I think they mediate and regulate a good chunk of scrambler metabolism. What we've got back in the hold is a couple of creatures dragged out of their element and holding their breath. And they can't hold it forever." (267-268)

Let me say that again—the scramblers are extremely intelligent, but *non-sentient*. The book discusses this at length, raising the questions: "*Why* did humans evolve to have consciousness? Is consciousness actually beneficial, or just a local maximum?" See the "Interesting Quotes" section at the end of this post for more about this.

Now back to the plot. The end of the book is a bit chaotic, and basically ends with *Rorschach* and *Theseus* blowing each other up. However, Siri Keeton escapes on a smaller ship—the Captain tasked him with a final mission of explaining the alien lifeforms to humans back on earth.

## Opinions
There's lots of interesting ideas and concepts scattered throughout *Blindsight*. For example, there's "Transient Attitudinal Tweak" (see page 163), a process where someone with *write access* to your brain can change your attitude, e.g. make you more happy. There's also "Heaven", which is basically just very good VR (note that people who haven't "died" yet can still visit you!). While interesting, these concepts serve as decoration for the book's main idea—that sentience is overrated.

The book can really be summed in a single sentence: what happens when humanity makes first contact with aliens who are extremely intelligent, but not sentient? However, *Blindsight* doesn't just throw this idea in your face. It builds up to it over the course of the book, and only directly discusses it towards the very end. What do I mean by "it builds up to it"? Well, the book's protagonist is a self-described Chinese Room—he can translate, but not understand.

> I knew all about Chinese Rooms. I was one. I didn't even keep it a secret, I told anyone who was interested enough to ask. (114)

*Theseus*'s captain is a non-sentient (well, as far as we know) AI. And the ship's attack unit is a horde of non-sentient drones. By the time we meet the scramblers, we have already been exposed to a number of non-sentient beings that play a key role in the story.

We've been talking a lot about sentience and consciousness. But what *is* consciousness? Well, I don't have a great answer for that, and (afaik) there isn't a generally agreed upon definition. So let's just treat it like the [Supreme Court treated porn—you know it when you see it](https://en.wikipedia.org/wiki/I_know_it_when_I_see_it). *It's actually a lot more complicated than that—who can really say that someone else is conscious? Maybe [I'm the only person that exists](https://en.wikipedia.org/wiki/Solipsism), and everyone else is just a simulation. But disregarding this, I think most people can point to humans and say "we're conscious" and point to rocks and say "they're not". There's a big gray area in between, but at the extremes people generally agree.*

Even if we generally, hand-wavily agree on *what* consciousness is, there's the question of *why*. I had never seen this question raised in anything else I've read, and had never come to think of it myself. I guess I'd always just assumed that it was obvious—humans have dominated earth, humans have consciousness, consciousness *must* be good. And it is good, to some extent. But is it *better* than non-conscious alternatives, or is it just a local maximum? That's the question this book raises, and to be honest I don't have a great answer.

However, I am leaning towards the "local maximum" answer—with the current developments in AI, this is certainly the way things appear to be trending. For example, we've already created AIs that dominate us in games like Go and Chess. These AIs are not sentient (as far as we can tell), and so non-sentient > sentient is already true for certain skills. Now, with models like ChatGPT and Stable Diffusion, AI is also rapidly approaching our creative skills like writing and drawing. If we continue to extrapolate, it seems reasonable that a non-sentient AI could be better at humans in basically everything (for more on this, read this great [Wait But Why](https://waitbutwhy.com/2015/01/artificial-intelligence-revolution-2.html)).

My final parting thoughts—if you like scifi, read this book! Besides all the complicated vocabulary (I had to Google *a lot* of words), it's not too hard to follow, and the ideas it presents are novel and thought-provoking.

## Interesting Quotes
> There's a reason they call it *radical* hemispherectomy: half the brain thrown out with yesterday's krill, the remaining half press-ganged into double duty. Think of all the rewiring that one lonely hemisphere must have struggled with as it tried to take up the slack. It turned out to be okay, obviously. The brain's a very flexible piece of meat; it took some doing, but it adapted. *I* adapted. Still. Think of all that must have been squeezed out, deformed, *reshaped* by the time the renovations were through. You could argue that I'm a different person than the one who used to occupy this body. (17)

>The new Millennium changed all that. We've surpassed ourselves now, we're exploring terrain beyond the limits of merely human understanding. Sometimes its contours, even in conventional space, are just too intricate for our brains to track; other times its very axes extend into dimensions inconceivable to minds built to fuck and fight on some prehistoric grassland. So many things constrain us, from so many directions. The most altruistic and sustainable philosophies fail before the brute brainstem imperative of self-interest. Subtle and elegant equations *predict* the behavior of the quantum world, but none can *explain* it. After four thousand years we can't even prove that reality exists beyond the mind of the first-person dreamer. We have such need of intellects greater than our own. 
>
>But we're not very good at building them. The forced matings of minds and electrons succeed and fail with equal spectacle. Our hybrids become as brilliant as savants, and as autistic. We graft people to prosthetics, make their overloaded motor strips juggle meat and machinery, and shake our heads when their fingers twitch and their tongues stutter. Computers bootstrap their own offspring, grow so wise and incomprehensible that their communiqués assume the hallmarks of dementia: unfocused and irrelevant to the barely-intelligent creatures left behind.
> 
> And when your surpassing creations find the answers you asked for, you can't understand their analysis and you can't verify their answers. You have to take their word on faith—or you use information theory to *flatten* it for you, to squash the tesseract into two dimensions and the Klein bottle into three, to simplify reality and pray to whatever Gods survived the millennium that your honorable twisting of the truth hasn't ruptured any of its load-bearing pylons. You hire people like me; the crossbred progeny of profilers and proof assistants and information theorists.
> 
> In formal settings you'd call me *Synthesist*. On the street you call me *jargonaut* or *poppy*. If you're one of those savants whose hard-won truths are being bastardized and lobotomized for powerful know-nothings interested only in market share, you might call me a *mole* or a *chaperone*. (48-49)

> The only reason *we* were here was because nobody had yet optimized software for First Contact. (53)

> The point is they can do something that's neurologically impossible for us Humans. They can hold *simultaneous multiple worldviews*, Pod-man. They just *see* things we have to work out step-by-step, they don't have to *think* about it. (61)

> She reveled in her own inconsistency: a woman whose professional machinery edited thought itself, yet mistrustful of the dehumanizing impact of telephones. Innately affectionate, and innately afraid of unreturned affection, and indomitably unwilling to let any of that stop here. (65)

> Equidistant to the other two tribes sat the Historians. They didn't have too many thoughts on the probable prevalence of intelligent, spacefaring extraterrestrials—*but if there are any, they said, they're not just going to be smart. They're going to be* mean.
> 
> It might seem almost too obvious a conclusion. What is Human history, if not an ongoing succession of greater technologies grinding lesser ones beneath their boots? But the subject wasn't merely *Human* history, or the unfair advantage that tools gave to any given side; the oppressed snatch up advanced weaponry as readily as the oppressor, given half a chance. No, the real issue was how those tools got there in the first place. The real issue was what tools are *for*.
> 
> To the Historians, tools existed for only one reason: to force the universe into unnatural shapes. They treated nature as an enemy, they were by definition a rebellion against the way things were. Technology is a stunted thing in benign environments, it never thrived in any culture gripped by belief in natural harmony. Why invent fusion reactors if your climate is comfortable, if your food is abundant? Why build fortresses if you have no enemies? Why force change upon a world which poses no threat? 
> 
> Human civilization had a lot of branches, not so long ago. Even into the twenty-first century, a few isolated tribes had barely developed stone tools. Some settled down with agriculture. Others weren't content until they had ended nature itself, still others until they'd built cities in space. 
> 
> We all rested eventually, though. Each new technology trampled lesser ones, climbed to some complacent asymptote, and stopped— until my own mother packed herself away like a larva in honeycomb, softened by machinery, robbed of incentive by her own contentment. 
> 
> But history never said that everyone had to stop where we did. It only suggested that those who *had* stopped no longer struggled for existence. There could be other, more hellish worlds where the best Human technology would crumble, where the environment was still the enemy, where the only survivors were those who fought back with sharper tools and stronger empires. The threats contained in those environments would not be simple ones. Harsh weather and natural disasters either kill you or they don't, and once conquered—or adapted to— they lose their relevance. No, the only environmental factors that continued to matter were those that fought back, that countered new strategies with newer ones, that forced their enemies to scale ever-greater heights just to stay alive. Ultimately, the only enemy that mattered was an *intelligent* one. 
> 
> And if the best toys do end up in the hands of those who've never forgotten that life itself is an act of war against intelligent opponents, what does that say about a race whose machines travel between the stars? (79-80)

> "Well, according to game theory, you should never tell anyone when your birthday is." (83)

> "You're saying the brain's got some kind of *existence gauge*?"
> 
> "Brain's got all *kinds* of gauges. You can *know* you're blind even when you're not; you can *know* you can see, even when you're blind. And yeah, you can *know* you don't exist even when you do. It's a long list, commissar." (180)

> There was more, a whole catalog of finely-tuned dysfunctions that *Rorschach* had not yet inflicted on us. Somnambulism. Agnosias. Hemineglect. ConSensus served up a freak show to make any mind reel at its own fragility: a woman dying of thirst within easy reach of water, not because she couldn't see the faucet but because she couldn't *recognize* it. A man for whom the left side of the universe did not exist, who could neither perceive nor conceive of the left side of his body, of a room, of a line of text. A man for whom the very concept of *leftness* had become literally unthinkable. (192)

> They never really talked like that, by the way. You'd hear gibberish—a half-dozen languages, a whole Babel of personal idioms—if I spoke in their real voices. 
> 
> Some of the simpler tics make it through: Sascha's good-natured belligerence, Sarasti's aversion to the past tense. Cunningham lost most of his gender pronouns to an unforeseen glitch during the work on his temporal lobe. But it went beyond that. The whole lot of them threw English and Hindi and Hadzane into every second sentence; no real scientist would allow their thoughts to be hamstrung by the conceptual limitations of a single language. Other times they acted almost as synthesists in their own right, conversing in grunts and gestures that would be meaningless to any baseline. It's not so much that the bleeding edge lacks social skills; it's just that once you get past a certain point, formal speech is too damn slow. 
> 
> Except for Susan James. The walking contradiction, the woman so devoted to Communication As Unifier that she'd cut her own brain into disunified chunks to make the point. She was the only one who ever seemed to care who she was talking to. The others spoke only for themselves, even when they spoke to each other. Even James's other cores would speak their own minds in their own way, and let everyone else translate as best they could. It wasn't a problem. Everyone on Theseus could read everyone else. 
> 
> But that didn't matter to Susan James. She fit each of her words to their intended recipient, she *accommodated*. 
> 
> I am a conduit. I exist to bridge the gap, and I'd bridge nothing if I only told you what these people said. So I am telling you what they *meant*, and it will mean as much to you as you can handle. 
> 
> Except for Susan James, linguist and Ringleader, whom I trust to speak for herself. (203-204)

> Yeah. *Lone* excursions. Forced to either split the group or cover less ground, we were to split the group. We were speedcartographers panning for gold. Everything we did here was an act of faith: faith that the unifying principles of *Rorschach*'s internal architecture could be derived from the raw dimensions we'd grab on the run. Faith that *Rorschach*'s internal architecture even *had* unifying principles. Earlier generations had worshipped malign and capricious spirits. Ours put its faith in an ordered universe. Here in the Devil's Baklava, it was easy to wonder if our ancestors hadn't been closer to the mark. (216)

> "I don't actually remember the dreams when I wake up anymore."
> 
> "So how do you know you still have them?" Pag asked.
> 
> *Fuck it*, I thought, and tipped back the last of my pint in a single gulp. "I know."
> 
> "How?"
> 
> I frowned, taken aback. I had to think for a few moments before I remembered.
> 
> "I wake up smiling," I said. (234)

> "Vision's mostly a lie anyway," he continued. "We don't really see anything except a few hi-res degrees where the eye focuses. Everything else is just peripheral blur, just— light and motion. Motion draws the focus. And your eyes *jiggle* all the time, did you know that, Keeton? *Saccades*, they're called. Blurs the image, the movement's way too fast for the brain to integrate so your eye just —shuts down between pauses. It only grabs these isolated freezeframes, but your brain edits out the blanks and stitches an — an illusion of continuity into your head." 
> 
> He turned to face me. "And you know what's *really* amazing? If something only moves during the gaps, your brain just—ignores it. It's invisible." (281)

> "For starters, the *dumbest* of these things can look into your head and see what parts of your visual cortex are lighting up. And if there's a difference between that and mind-reading, it's not much of one." 
> 
> "As long as we stay out of *Rorschach*—" 
> 
> "That ship has *sailed*. You people have already been there. Repeatedly. Who knows what you already did down there for no better reason than because *Rorschach made* you?" 
> 
> "Wait a second," Bates objected. "None of us were *puppets* down there. We hallucinated and we went blind and—and crazy even, but we were never *possessed*." 
> 
> Cunningham looked at her and snorted. "You think you'd be able to fight the strings? You think you'd even *feel* them? I could apply a transcranial magnet to your head right now and you'd raise your middle finger or wiggle your toes or kick Siri here in the sack and then swear on your sainted mother's grave that you only did it because you *wanted* to. You'd dance like a puppet and all the time swear you were doing it of your own free will, and that's just *me*, that's just some borderline OCD with a couple of magnets and an MRI helmet." He waved at the vast unknowable void beyond the bulkhead. Shreds of mangled cigarette floated sideways in front of him. "Do you want to guess what *that* can do? For all we know we've already given them *Theseus*' technical specs, warned them about the Icarus array, and then just decided *of our own free will* to forget it all." 
> 
> "We can cause those effects," Sarasti said coolly. "As you say. Strokes cause them. Tumors. Random accidents." 
> 
> "*Random*? Those were *experiments*, people! That was *vivisection*! They let you in so they could take you apart and see what made you tick and you never even *knew* it." (287)

> "Brains are survival engines, not truth detectors. If self-deception promotes fitness, the brain lies. Stops noticing— irrelevant things. Truth never matters. Only fitness. By now you don't experience the world as it exists at all. You experience a simulation built from assumptions. Shortcuts. *Lies*. Whole *species* is agnosiac by default. *Rorschach* does nothing to you that you don't already do to yourselves." (288)

> They'd hoped, by now, to have banished sleep forever. 
> 
> The waste was nothing short of obscene: a third of every Human life spent with its strings cut, insensate, the body burning fuel but not *producing*. Think of all we could accomplish if we didn't have to lapse into unconsciousness every fifteen hours or so, if our minds could stay awake and alert from the moment of infancy to that final curtain call a hundred twenty years later. Think of eight billion souls with no off switch and no down time until the very chassis wore out. 
> 
> Why, we could go to the stars. 
> 
> It hadn't worked out that way. Even if we'd outgrown the need to stay quiet and hidden during the dark hours—the only predators left were those we'd brought back ourselves—the brain still needed time apart from the world outside. Experiences had to be catalogued and filed, mid-term memories promoted to long-term ones, free radicals swept from their hiding places among the dendrites. We had only reduced the need for sleep, not eliminated it—and that incompressible residue of downtime seemed barely able to contain the dreams and phantoms left behind. They squirmed in my head like creatures in a draining tidal pool. (294-295)

> Insight, then. Wisdom. The quest for knowledge, the derivation of theorems, science and technology and all those exclusively *human* pursuits that must surely rest on a conscious foundation. Maybe that's what sentience would be for— if scientific breakthroughs didn't spring fully-formed from the *sub*conscious mind, manifest themselves in dreams, as full-blown insights after a deep night's sleep. It's the most basic rule of the stymied researcher: *stop thinking about the problem*. Do something else. It will come to you if you just stop being *conscious* of it. 
> 
> Every concert pianist knows that the surest way to ruin a performance is to be aware of what the fingers are doing. Every dancer and acrobat knows enough to let the mind *go*, let the body run itself. Every driver of any manual vehicle arrives at destinations with no recollection of the stops and turns and roads traveled in getting there. You are all sleepwalkers, whether climbing creative peaks or slogging through some mundane routine for the thousandth time. You are all sleepwalkers.
>  
>  Don't even *try* to talk about the learning curve. Don't bother citing the months of deliberate practice that precede the unconscious performance, or the years of study and experiment leading up to the gift-wrapped Eureka moment. So what if your lessons are all learned consciously? Do you think that proves there's no other way? Heuristic software's been learning from experience for over a hundred years. Machines master chess, cars learn to drive themselves, statistical programs face problems and design the experiments to solve them and you think that the only path to learning leads through *sentience*? You're Stone-age nomads, eking out some marginal existence on the veldt—denying even the possibility of agriculture, because hunting and gathering was good enough for your parents. 
>  
>  Do you want to know what consciousness is for? Do you want to know the only *real* purpose it serves? Training wheels. You can't see both aspects of the Necker Cube at once, so it lets you focus on one and dismiss the other. That's a pretty half-assed way to parse reality. You're always better off looking at more than one side of *anything*. Go on, try. Defocus. It's the next logical step. 
>  
>  Oh, but you can't. There's something in the way. 
>  
>  And it's fighting back. (301-303)

> *I* wastes energy and processing power, self-obsesses to the point of psychosis. Scramblers have no need of it, scramblers are more parsimonious. With simpler biochemistries, with smaller brains— deprived of tools, of their ship, even of parts of their own metabolism—they think rings around you. They hide their language in plain sight, even when you know what they're saying. They turn your own cognition against itself. *They travel between the stars*. This is what intelligence can do, unhampered by selfawareness. 
> 
> *I* is not the working mind, you see. For Amanda Bates to say "I do not exist" would be nonsense; but when the processes beneath say the same thing, they are merely reporting that the parasites have died. They are only saying that they are free (304)

> You have a naive understanding of evolutionary processes. There's no such thing as *survival of the fittest. Survival of the most adequate*, maybe. It doesn't matter whether a solution's optimal. All that matters is whether it beats the alternatives. (306)

> "As long as you pull your hand away from an open flame, who cares whether you do it because it *hurts* or because some feedback algorithm says *withdraw if heat flux exceeds critical T*? Natural selection doesn't care about *motives*. If impersonating something increases fitness, then nature will select good impersonators over bad ones. Keep it up long enough and no conscious being would be able to pick your zombie out of a crowd." Another silence; I could hear him chewing through it. "It'll even be able to participate in a conversation like this one. It could write letters home, impersonate real human feelings, without having the slightest awareness of its own existence." (311)

> All of them, I began to realize, had missed the point. All those theories, all those drugdreams and experiments and models trying to prove what consciousness *was*: none to explain what it was *good* for. None needed: obviously, consciousness makes us what we are. It lets us see the beauty and the ugliness. It elevates us into the exalted realm of the spiritual. Oh, a few outsiders— Dawkins, Keogh, the occasional writer of hackwork fiction who barely achieved obscurity—wondered briefly at the why of it: why *not* soft computers, and no more? Why should nonsentient systems be inherently inferior? But they never really raised their voices above the crowd. The value of what we are was too trivially selfevident to ever call into serious question. 
> 
> Yet the questions persisted, in the minds of the laureates, in the angst of every horny fifteen-year-old on the planet. Am I nothing but sparking chemistry? Am I a magnet in the ether? I am more than my eyes, my ears, my tongue; I am the little thing *behind* those things, the thing looking out from inside. But who looks out from its eyes? What does it reduce to? Who am I? Who am I? *Who am I?* (314)

> "They're not even *hostile*". Not even capable of hostility. Just so profoundly alien that they couldn't help but treat human language itself as a form of combat. (325)

> So I talk to myself, dictate history and opinion from real hemisphere to synthetic one: bright brief moments of awareness, long years of oblivious decay between. Maybe the whole exercise is pointless from the start, maybe no one's even listening. 
> 
> It doesn't matter. This is what I *do*. 
> 
> So there you have it: a memoir told from meat to machinery. A tale told to myself, for lack of someone else to take an interest. 
> 
> Anyone with half a brain could tell it. (357-358)